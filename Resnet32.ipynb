{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python38264bita9fe091a7e544366b49cd42eea3180f6",
      "display_name": "Python 3.8.2 64-bit"
    },
    "colab": {
      "name": "Resnet32.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darshank528/Project-STORM/blob/master/Resnet32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyi1LjnXldsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "\n",
        "#setting device configuration\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
        "\n",
        "def ResNet32():\n",
        "  class Basic_Module(nn.Module):\n",
        "    #Basic Block with identity maps as shortcuts\n",
        "    def __init__(self,in_channel,out_channel,stride=1):\n",
        "      super(Basic_Module,self).__init__()\n",
        "      self.conv1 = nn.Conv2d(in_channel,out_channel,kernel_size=3,stride=stride,padding=1,bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "      self.conv2 = nn.Conv2d(out_channel,out_channel,kernel_size=3,padding=1,bias=False)\n",
        "      self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "      self.shortcut = nn.Sequential()\n",
        "\n",
        "      if stride!=1 or in_channel!=out_channel:\n",
        "        self.shortcut = nn.Sequential(\n",
        "                          nn.Conv2d(in_channel,out_channel,kernel_size=1,stride=stride,bias=False),\n",
        "                          nn.BatchNorm2d(out_channel))\n",
        "\n",
        "    def forward(self,x):\n",
        "      x_shortcut = x    \n",
        "      x = torch.celu(self.bn1(self.conv1(x)),alpha=0.075)\n",
        "      x = self.bn2(self.conv2(x))\n",
        "      x_shortcut = self.shortcut(x_shortcut)\n",
        "      #creating a shortcut connection\n",
        "      x = x + x_shortcut\n",
        "      x = torch.celu(x,alpha=0.075)\n",
        "      return x\n",
        "\n",
        "  class Bottleneck_Module(nn.Module):\n",
        "    #Bottleneck block with identity map as shortcuts\n",
        "    def __init__(self,in_channel,out_channel,stride=1):\n",
        "      super(Bottleneck_Module,self).__init__()\n",
        "      self.conv1 = nn.Conv2d(in_channel,out_channel,kernel_size=1,padding=0,bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "      self.conv2 = nn.Conv2d(out_channel,out_channel,kernel_size=3,padding=1,bias=False)\n",
        "      self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "      self.conv3 = nn.Conv2d(out_channel,out_channel,kernel_size=1,padding=0,bias=False,stride=stride)\n",
        "      self.bn3 = nn.BatchNorm2d(out_channel)\n",
        "      self.shortcut = nn.Sequential()\n",
        "\n",
        "      if stride!=1 or in_channel!=out_channel:\n",
        "        self.shortcut = nn.Sequential(\n",
        "                          nn.Conv2d(in_channel,out_channel,kernel_size=1,stride=stride,bias=False),\n",
        "                          nn.BatchNorm2d(out_channel))\n",
        "\n",
        "    def forward(self,x):\n",
        "      x_shortcut = x\n",
        "      x = torch.celu(self.bn1(self.conv1(x)),alpha=0.075)\n",
        "      x = torch.celu(self.bn2(self.conv2(x)),alpha=0.075)\n",
        "      x = self.bn3(self.conv3(x))\n",
        "      x_shortcut = self.shortcut(x_shortcut)\n",
        "      #creating a shortcut connection\n",
        "      x = x + x_shortcut\n",
        "      x = torch.celu(x,alpha=0.075)\n",
        "      return x\n",
        "\n",
        "  class ResNet(nn.Module):\n",
        "    #main resnet model\n",
        "    def __init__(self,block,filter_map,n,classes=10):\n",
        "      super(ResNet,self).__init__()\n",
        "      self.conv1 = nn.Conv2d(3,filter_map[0],kernel_size=3,padding=1,bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(filter_map[0])\n",
        "      self.block1 = self.MakeResnetLayer(block,(filter_map[0],filter_map[0]),n,stride=1)\n",
        "      self.block2 = self.MakeResnetLayer(block,(filter_map[0],filter_map[1]),n,stride=2)\n",
        "      self.block3 = self.MakeResnetLayer(block,(filter_map[1],filter_map[2]),n,stride=2)\n",
        "      self.GloabalAveragePool = nn.AdaptiveAvgPool2d(2)\n",
        "      self.fc = nn.Linear(2*2*filter_map[2],classes,bias=True)  \n",
        "\n",
        "    def MakeResnetLayer(self,block,filters,n,stride):\n",
        "      #defining filters\n",
        "      in_channel,out_channel = filters\n",
        "      #layers to be added at given stage\n",
        "      layer = []\n",
        "      layer.append(block(in_channel,out_channel,stride))\n",
        "      for i in range(n-1):\n",
        "        layer.append(block(out_channel,out_channel))\n",
        "      #stacking all layers\n",
        "      SubBlock = nn.Sequential(*layer)\n",
        "      return SubBlock\n",
        "\n",
        "    def forward(self,x):\n",
        "      #initial layers\n",
        "      x = torch.relu(self.bn1(self.conv1(x)))\n",
        "      #stage1\n",
        "      x = self.block1(x)\n",
        "      #stage2\n",
        "      x = self.block2(x)\n",
        "      #stage3\n",
        "      x = self.block3(x)\n",
        "      #final layers\n",
        "      x = self.GloabalAveragePool(x)\n",
        "      x = x.view(-1,2*2*64)\n",
        "      x = self.fc(x)\n",
        "      return x\n",
        "   \n",
        "  #creating an object of resnet model and pushing it to device(CPU/GPU)\n",
        "  model1 = ResNet(Basic_Module,[16,32,64],5).to(device)\n",
        "  model2 = ResNet(Bottleneck_Module,[16,32,64],5).to(device)\n",
        "  return model1,model2\n",
        "\n",
        "#defining models\n",
        "ModelBasic,ModelBottleneck = ResNet32()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-CMRTlLldsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e66c6a40-50e0-4ea4-e831-5fb16f909ec2"
      },
      "source": [
        "#what resnet basic model look like\n",
        "summary(ModelBasic,(3,32,32))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
            "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
            "      Basic_Module-7           [-1, 16, 32, 32]               0\n",
            "            Conv2d-8           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-9           [-1, 16, 32, 32]              32\n",
            "           Conv2d-10           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
            "     Basic_Module-12           [-1, 16, 32, 32]               0\n",
            "           Conv2d-13           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-14           [-1, 16, 32, 32]              32\n",
            "           Conv2d-15           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
            "     Basic_Module-17           [-1, 16, 32, 32]               0\n",
            "           Conv2d-18           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
            "           Conv2d-20           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-21           [-1, 16, 32, 32]              32\n",
            "     Basic_Module-22           [-1, 16, 32, 32]               0\n",
            "           Conv2d-23           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-24           [-1, 16, 32, 32]              32\n",
            "           Conv2d-25           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-26           [-1, 16, 32, 32]              32\n",
            "     Basic_Module-27           [-1, 16, 32, 32]               0\n",
            "           Conv2d-28           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-29           [-1, 32, 16, 16]              64\n",
            "           Conv2d-30           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-31           [-1, 32, 16, 16]              64\n",
            "           Conv2d-32           [-1, 32, 16, 16]             512\n",
            "      BatchNorm2d-33           [-1, 32, 16, 16]              64\n",
            "     Basic_Module-34           [-1, 32, 16, 16]               0\n",
            "           Conv2d-35           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-36           [-1, 32, 16, 16]              64\n",
            "           Conv2d-37           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-38           [-1, 32, 16, 16]              64\n",
            "     Basic_Module-39           [-1, 32, 16, 16]               0\n",
            "           Conv2d-40           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-41           [-1, 32, 16, 16]              64\n",
            "           Conv2d-42           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "     Basic_Module-44           [-1, 32, 16, 16]               0\n",
            "           Conv2d-45           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-46           [-1, 32, 16, 16]              64\n",
            "           Conv2d-47           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-48           [-1, 32, 16, 16]              64\n",
            "     Basic_Module-49           [-1, 32, 16, 16]               0\n",
            "           Conv2d-50           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-51           [-1, 32, 16, 16]              64\n",
            "           Conv2d-52           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
            "     Basic_Module-54           [-1, 32, 16, 16]               0\n",
            "           Conv2d-55             [-1, 64, 8, 8]          18,432\n",
            "      BatchNorm2d-56             [-1, 64, 8, 8]             128\n",
            "           Conv2d-57             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-58             [-1, 64, 8, 8]             128\n",
            "           Conv2d-59             [-1, 64, 8, 8]           2,048\n",
            "      BatchNorm2d-60             [-1, 64, 8, 8]             128\n",
            "     Basic_Module-61             [-1, 64, 8, 8]               0\n",
            "           Conv2d-62             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-63             [-1, 64, 8, 8]             128\n",
            "           Conv2d-64             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-65             [-1, 64, 8, 8]             128\n",
            "     Basic_Module-66             [-1, 64, 8, 8]               0\n",
            "           Conv2d-67             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-68             [-1, 64, 8, 8]             128\n",
            "           Conv2d-69             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-70             [-1, 64, 8, 8]             128\n",
            "     Basic_Module-71             [-1, 64, 8, 8]               0\n",
            "           Conv2d-72             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-73             [-1, 64, 8, 8]             128\n",
            "           Conv2d-74             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-75             [-1, 64, 8, 8]             128\n",
            "     Basic_Module-76             [-1, 64, 8, 8]               0\n",
            "           Conv2d-77             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-78             [-1, 64, 8, 8]             128\n",
            "           Conv2d-79             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
            "     Basic_Module-81             [-1, 64, 8, 8]               0\n",
            "AdaptiveAvgPool2d-82             [-1, 64, 2, 2]               0\n",
            "           Linear-83                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 468,826\n",
            "Trainable params: 468,826\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.91\n",
            "Params size (MB): 1.79\n",
            "Estimated Total Size (MB): 7.71\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNuJomyhlds8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aba00cd0-80bb-41c3-ad90-266b19e3fc0e"
      },
      "source": [
        "#what resnet bottleneck model look like\n",
        "summary(ModelBottleneck,(3,32,32))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3           [-1, 16, 32, 32]             256\n",
            "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
            "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
            "            Conv2d-7           [-1, 16, 32, 32]             256\n",
            "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
            " Bottleneck_Module-9           [-1, 16, 32, 32]               0\n",
            "           Conv2d-10           [-1, 16, 32, 32]             256\n",
            "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
            "           Conv2d-12           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-13           [-1, 16, 32, 32]              32\n",
            "           Conv2d-14           [-1, 16, 32, 32]             256\n",
            "      BatchNorm2d-15           [-1, 16, 32, 32]              32\n",
            "Bottleneck_Module-16           [-1, 16, 32, 32]               0\n",
            "           Conv2d-17           [-1, 16, 32, 32]             256\n",
            "      BatchNorm2d-18           [-1, 16, 32, 32]              32\n",
            "           Conv2d-19           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-20           [-1, 16, 32, 32]              32\n",
            "           Conv2d-21           [-1, 16, 32, 32]             256\n",
            "      BatchNorm2d-22           [-1, 16, 32, 32]              32\n",
            "Bottleneck_Module-23           [-1, 16, 32, 32]               0\n",
            "           Conv2d-24           [-1, 16, 32, 32]             256\n",
            "      BatchNorm2d-25           [-1, 16, 32, 32]              32\n",
            "           Conv2d-26           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-27           [-1, 16, 32, 32]              32\n",
            "           Conv2d-28           [-1, 16, 32, 32]             256\n",
            "      BatchNorm2d-29           [-1, 16, 32, 32]              32\n",
            "Bottleneck_Module-30           [-1, 16, 32, 32]               0\n",
            "           Conv2d-31           [-1, 16, 32, 32]             256\n",
            "      BatchNorm2d-32           [-1, 16, 32, 32]              32\n",
            "           Conv2d-33           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-34           [-1, 16, 32, 32]              32\n",
            "           Conv2d-35           [-1, 16, 32, 32]             256\n",
            "      BatchNorm2d-36           [-1, 16, 32, 32]              32\n",
            "Bottleneck_Module-37           [-1, 16, 32, 32]               0\n",
            "           Conv2d-38           [-1, 32, 32, 32]             512\n",
            "      BatchNorm2d-39           [-1, 32, 32, 32]              64\n",
            "           Conv2d-40           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-41           [-1, 32, 32, 32]              64\n",
            "           Conv2d-42           [-1, 32, 16, 16]           1,024\n",
            "      BatchNorm2d-43           [-1, 32, 16, 16]              64\n",
            "           Conv2d-44           [-1, 32, 16, 16]             512\n",
            "      BatchNorm2d-45           [-1, 32, 16, 16]              64\n",
            "Bottleneck_Module-46           [-1, 32, 16, 16]               0\n",
            "           Conv2d-47           [-1, 32, 16, 16]           1,024\n",
            "      BatchNorm2d-48           [-1, 32, 16, 16]              64\n",
            "           Conv2d-49           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-50           [-1, 32, 16, 16]              64\n",
            "           Conv2d-51           [-1, 32, 16, 16]           1,024\n",
            "      BatchNorm2d-52           [-1, 32, 16, 16]              64\n",
            "Bottleneck_Module-53           [-1, 32, 16, 16]               0\n",
            "           Conv2d-54           [-1, 32, 16, 16]           1,024\n",
            "      BatchNorm2d-55           [-1, 32, 16, 16]              64\n",
            "           Conv2d-56           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-57           [-1, 32, 16, 16]              64\n",
            "           Conv2d-58           [-1, 32, 16, 16]           1,024\n",
            "      BatchNorm2d-59           [-1, 32, 16, 16]              64\n",
            "Bottleneck_Module-60           [-1, 32, 16, 16]               0\n",
            "           Conv2d-61           [-1, 32, 16, 16]           1,024\n",
            "      BatchNorm2d-62           [-1, 32, 16, 16]              64\n",
            "           Conv2d-63           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-64           [-1, 32, 16, 16]              64\n",
            "           Conv2d-65           [-1, 32, 16, 16]           1,024\n",
            "      BatchNorm2d-66           [-1, 32, 16, 16]              64\n",
            "Bottleneck_Module-67           [-1, 32, 16, 16]               0\n",
            "           Conv2d-68           [-1, 32, 16, 16]           1,024\n",
            "      BatchNorm2d-69           [-1, 32, 16, 16]              64\n",
            "           Conv2d-70           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-71           [-1, 32, 16, 16]              64\n",
            "           Conv2d-72           [-1, 32, 16, 16]           1,024\n",
            "      BatchNorm2d-73           [-1, 32, 16, 16]              64\n",
            "Bottleneck_Module-74           [-1, 32, 16, 16]               0\n",
            "           Conv2d-75           [-1, 64, 16, 16]           2,048\n",
            "      BatchNorm2d-76           [-1, 64, 16, 16]             128\n",
            "           Conv2d-77           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-78           [-1, 64, 16, 16]             128\n",
            "           Conv2d-79             [-1, 64, 8, 8]           4,096\n",
            "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
            "           Conv2d-81             [-1, 64, 8, 8]           2,048\n",
            "      BatchNorm2d-82             [-1, 64, 8, 8]             128\n",
            "Bottleneck_Module-83             [-1, 64, 8, 8]               0\n",
            "           Conv2d-84             [-1, 64, 8, 8]           4,096\n",
            "      BatchNorm2d-85             [-1, 64, 8, 8]             128\n",
            "           Conv2d-86             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-87             [-1, 64, 8, 8]             128\n",
            "           Conv2d-88             [-1, 64, 8, 8]           4,096\n",
            "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
            "Bottleneck_Module-90             [-1, 64, 8, 8]               0\n",
            "           Conv2d-91             [-1, 64, 8, 8]           4,096\n",
            "      BatchNorm2d-92             [-1, 64, 8, 8]             128\n",
            "           Conv2d-93             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-94             [-1, 64, 8, 8]             128\n",
            "           Conv2d-95             [-1, 64, 8, 8]           4,096\n",
            "      BatchNorm2d-96             [-1, 64, 8, 8]             128\n",
            "Bottleneck_Module-97             [-1, 64, 8, 8]               0\n",
            "           Conv2d-98             [-1, 64, 8, 8]           4,096\n",
            "      BatchNorm2d-99             [-1, 64, 8, 8]             128\n",
            "          Conv2d-100             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-101             [-1, 64, 8, 8]             128\n",
            "          Conv2d-102             [-1, 64, 8, 8]           4,096\n",
            "     BatchNorm2d-103             [-1, 64, 8, 8]             128\n",
            "Bottleneck_Module-104             [-1, 64, 8, 8]               0\n",
            "          Conv2d-105             [-1, 64, 8, 8]           4,096\n",
            "     BatchNorm2d-106             [-1, 64, 8, 8]             128\n",
            "          Conv2d-107             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-108             [-1, 64, 8, 8]             128\n",
            "          Conv2d-109             [-1, 64, 8, 8]           4,096\n",
            "     BatchNorm2d-110             [-1, 64, 8, 8]             128\n",
            "Bottleneck_Module-111             [-1, 64, 8, 8]               0\n",
            "AdaptiveAvgPool2d-112             [-1, 64, 2, 2]               0\n",
            "          Linear-113                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 302,266\n",
            "Trainable params: 302,266\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.22\n",
            "Params size (MB): 1.15\n",
            "Estimated Total Size (MB): 10.39\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0TTEGiElsIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}